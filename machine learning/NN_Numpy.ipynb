{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NN_Numpy.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"aGfhEk6u1vw_","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt \n","\n","def sigmoid(z):\n","    return (1/(1+np.exp(-z)))\n","\n","def tanh(z):\n","    return (np.exp(z) - np.exp(-z)) / (np.exp(z) + np.exp(-z))\n","  \n","#input data\n","X =np.array([[0,0,1,1,1],\n","             [1,1,0,1,1],\n","             [1,1,1,0,0],\n","             [1,0,1,1,0],\n","             [1,1,1,1,0],\n","             [1,1,1,1,1]],dtype=float).T\n","#labels\n","Y = np.array([[0,1,0,1,0,1]],dtype=float)\n","#weight mtrix\n","w = 2*np.random.random((5,1)) - 1\n","#learning rate\n","np.random.seed(1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qaJunqqZ15OH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2b34ba7b-2bb7-4bb5-e8aa-fb1f4bc5d340","executionInfo":{"status":"ok","timestamp":1540120002565,"user_tz":-330,"elapsed":3236,"user":{"displayName":"Pratik Patil","photoUrl":"","userId":"17519623449250728281"}}},"cell_type":"code","source":["def LR_with_gradient_descent(X,Y,w):\n","    b,j=0,0\n","    m=len(X)\n","    learning_rate = 0.01\n","    for iter in range(50000):  \n","        #forward propagation\n","        z = np.dot(w.T,X) + b\n","        A = sigmoid(z)\n","        #cost function\n","        j = (-1 / m)*(np.sum(Y * np.log(A) + (1 - Y) * (np.log(1 - A))))\n","        #print(j)\n","        #backward propagation\n","        dz = A - Y\n","        dw =  (1 / m)*np.dot(X,dz.T)\n","        db =  (1 / m)*np.sum(dz)\n","        #updating weights and bias\n","        w = w - (learning_rate*dw)\n","        b = b - (learning_rate*db)\n","        \n","    return j\n","    \n","cost_lr=LR_with_gradient_descent(X,Y,w)\n","print(\"Logistic Regression Cost:\",cost_lr)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Logistic Regression Cost: 0.06050901164796692\n"],"name":"stdout"}]},{"metadata":{"id":"Z4DJ6rhc4x_i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2fd7abd9-7864-4e4f-af86-1271c3bbd654","executionInfo":{"status":"ok","timestamp":1540120009009,"user_tz":-330,"elapsed":6402,"user":{"displayName":"Pratik Patil","photoUrl":"","userId":"17519623449250728281"}}},"cell_type":"code","source":["def two_layer_nn(X,Y):\n","    m,j,learning_rate=len(X),0,0.01\n","    for iter in range(50000): \n","        #forward propagation\n","        w1 = 2*np.random.random((6,5)) - 1\n","        b1 = 2*np.random.random((6,1)) - 1\n","        layer1_z = np.dot(w1,X)+b1\n","        layer1_A = tanh(layer1_z)\n","        #print(layer1_A)\n","        w2 = 2*np.random.random((1,6)) - 1\n","        b2 = 0\n","        layer2_z = np.dot(w2,layer1_A)+b2\n","        #print(layer2_z)\n","        layer2_A = sigmoid(layer2_z)\n","        #print(layer2_A)\n","        \n","        #cost function\n","        prob = np.multiply(np.log(layer2_A), Y) + np.multiply((1 - Y), np.log(1 - layer2_A))\n","        j = (1 / m)*(j - (np.sum(prob) / m))\n","        #print(j)\n","        \n","        #backward propagation\n","        layer2_dz = layer2_A - Y\n","        layer2_dw2 = (1 / m)*np.dot(layer2_dz,layer1_A.T)\n","        layer2_db2 = (1 / m)*np.sum(layer2_dz,axis = 0,keepdims = True)\n","\n","        layer1_dz = np.multiply(np.dot(w2.T,layer2_dz), 1 - np.power(layer1_A,2))\n","        layer1_dw1 = (1 / m)*np.dot(layer1_dz,X.T)\n","        layer1_db1 = (1 / m)*np.sum(layer1_dz,axis = 0,keepdims = True)\n","    \n","        #update weights and bias\n","        w1 = w1 - (learning_rate*layer1_dw1)\n","        b1 = b1 - (learning_rate*layer1_db1)\n","        w2 = w2 - (learning_rate*layer2_dw2)\n","        b2 = b2 - (learning_rate*layer2_db2)\n","    \n","    return j\n","\n","  \n","cost_two_nn=two_layer_nn(X,Y)\n","print(\"Two layer Neural network cost:\",cost_two_nn)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Two layer Neural network cost: 0.21939053332751246\n"],"name":"stdout"}]}]}